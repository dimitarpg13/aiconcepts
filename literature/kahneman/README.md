# kahneman

This repo is dedicated to the book of Daniel Kahneman **"Thinking Fast and Slow"** as well as the common work of Daniel Kahneman and Amos Tversky.

Related to the topics discussed in the book is a very interesting conversation between Daniel Kahneman and Yann LeCun on the topic of understanding/deconstructing human intelligence:

https://youtu.be/oy9FhisFTmI

To summarize:
- our understanding of what intelligence is incomplete
- we do not know how to build algorithms which generalize
- we do not know how to infer the structure of Bayesian networks

Articles by Amos Tversky and Daniel Kahneman:

* _Availability: Heuristic for Judging Frequency and Probability, 1973_
  The paper explores a judgemental heuristic in which a person evaluates the frequence of classes or the probability of events by availability, i.e. by the ease with which relevant instances come to mind. In general, availability is correlated with ecological frequency, but it is also affected by other factors. Consequently, the reliance on the availability heuristic leads to systematic biases. Such biases are demonstrated in the judged frequency of classes of words, of combinatorial outcomes, and of repeated events. The phenomenon of illusory correlation is explained as an availability bias. The effects of the availability of incidents and scenarios on subjective probability are discussed.

* _Judgement under Uncertainty: Heuristics and Biases: Biases in judgements reveal some heuristics of thinking under uncertainty, 1974_
  Many decisions are based on the beliefs concerning the likelihood of uncertain events such as the outcome of an election, the guilt of a defendant, or the future value of the dollar. These beliefs are usually expressed in statements such as _"I think that.."_,_"chances are ..."_, _"it is unlikely that ..."_, and so forth. Occasionally, beliefs concerning uncertain events are expressed in numerical form as odds or subjective probabilities. What determines such beliefs? How do people assess the probability of an uncertain event or the value of an uncertain quantity? This article shows that people rely on a limited number of heuristic principles which reduce the complex tasks of assessing probabilities and prediciting values to simpler judgemental operations. In general, these heurisitics are quite useful, but sometimes they lead to severe and systematic errors.      
  The subjective assessment of probability resembles the subjective assessment of physical quantities such as distance and size. These judgements are all based on data of limited validity, which are processed according to heuristic rules. For example, the apparent distance of an object is determined in part by its clarity. The more sharply the object is seen, the closer it appears to be. This rule has some validity, because in any given scene the more distant objects are seen less sharply than nearer objects. However, the reliance on this rule leads to systematic errors in the estimation of distance. Specifically, distances are often overestimated when visibility is poor because the contours of objects are blurred. On the other hand, distances are often underestimated when visibility is good because the objects are seen sharply. Thus, the reliance on clarity as an indication of distance leads to common biases. Such biases are also found in the intuitive judgement of probability. This article describes three heuristics employed to assess probabilities and to predict values. Biases to which these heuristics lead are enumerated, and the implications of these observations are discussed.

* _Prospect Theory: An Analysis of Decision Under Risk, 1979_
  This article presents a critique of expected utility theory as a descriptive model of decision making under risk, and develops an alternative model, called **prospect theory**. Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory. In particular, people underwieght outcomes that are merely probable in comparison with outcomes that are obtained with certainty. This tendency, called the certainty effect, contributes to risk aversion in choices involving sure gains and to risk seeking in choices involving sure losses. In addition, people generally discard components that are shared by all prospects under consideration. This tendency, called the isolation effect, leads to inconsistent preferences when the same choice is presented in different forms. An alternative theory of choice is developed, in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights. The value function is normally concave for gains, commonly convex for losses, and is generally steeper for losses than for gains. Decision weights are generally lower than the corresponding probabilities, except in the range of low probabilities. Overweighting of low probabilities may contribute to the attractiveness of both insurance and gambling.   
  

